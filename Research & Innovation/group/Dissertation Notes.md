---
annotation-target: TCD-SCSS-DISSERTATION-2022-023.pdf
---


>%%
>```annotation-json
>{"created":"2024-10-02T20:43:04.227Z","text":"Problem trying to solve","updated":"2024-10-02T20:43:04.227Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":1409,"end":1484},{"type":"TextQuoteSelector","exact":"Turning pages of sheet music is a common source of irritation for musicians","prefix":"ervisor: Dr. Kenneth Dawson-Howe","suffix":", andthis paper aims to address "}]}]}
>```
>%%
>*%%PREFIX%%ervisor: Dr. Kenneth Dawson-Howe%%HIGHLIGHT%% ==Turning pages of sheet music is a common source of irritation for musicians== %%POSTFIX%%, andthis paper aims to address*
>%%LINK%%[[#^4dzbn6rujw4|show annotation]]
>%%COMMENT%%
>Problem trying to solve
>%%TAGS%%
>
^4dzbn6rujw4



>%%
>```annotation-json
>{"created":"2024-10-02T20:44:23.481Z","text":"The method of solving it","updated":"2024-10-02T20:44:23.481Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":1614,"end":1754},{"type":"TextQuoteSelector","exact":"a tablet device and explores the viability ofusing gaze detection as a method of triggering automatic page turns in a sheet musicapplication","prefix":"lication has been developed for ","suffix":". Creating a passive interface w"}]}]}
>```
>%%
>*%%PREFIX%%lication has been developed for%%HIGHLIGHT%% ==a tablet device and explores the viability ofusing gaze detection as a method of triggering automatic page turns in a sheet musicapplication== %%POSTFIX%%. Creating a passive interface w*
>%%LINK%%[[#^867bnufg9a|show annotation]]
>%%COMMENT%%
>The method of solving it
>%%TAGS%%
>
^867bnufg9a


>%%
>```annotation-json
>{"created":"2024-10-02T20:48:00.054Z","text":"examine the performance of 2 gaze detection systems and 3 page-turning  systems","updated":"2024-10-02T20:48:00.054Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":1954,"end":2069},{"type":"TextQuoteSelector","exact":"the effect that various gaze detection solutions andpage-turning systems have on the performance of the application","prefix":"rns. In an effort to understand ","suffix":" two different gazedetection sol"}]}]}
>```
>%%
>*%%PREFIX%%rns. In an effort to understand%%HIGHLIGHT%% ==the effect that various gaze detection solutions andpage-turning systems have on the performance of the application== %%POSTFIX%%two different gazedetection sol*
>%%LINK%%[[#^sy64lsh2pnh|show annotation]]
>%%COMMENT%%
>examine the performance of 2 gaze detection systems and 3 page-turning  systems
>%%TAGS%%
>
^sy64lsh2pnh


>%%
>```annotation-json
>{"created":"2024-10-02T22:00:10.884Z","text":"lighting and positioning is serious challenge","updated":"2024-10-02T22:00:10.884Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":2407,"end":2526},{"type":"TextQuoteSelector","exact":" challenges with performinggaze detection in a general environment with uncontrolled lighting or positioning of theuser","prefix":"than others, and highlighted the","suffix":".Contents1 Introduction 21.1 Bac"}]}]}
>```
>%%
>*%%PREFIX%%than others, and highlighted the%%HIGHLIGHT%% ==challenges with performinggaze detection in a general environment with uncontrolled lighting or positioning of theuser== %%POSTFIX%%.Contents1 Introduction 21.1 Bac*
>%%LINK%%[[#^ie5hwd7d8x|show annotation]]
>%%COMMENT%%
>lighting and positioning is serious challenge
>%%TAGS%%
>
^ie5hwd7d8x


>%%
>```annotation-json
>{"created":"2024-10-02T22:03:47.682Z","text":"page turning is a long-time issue","updated":"2024-10-02T22:03:47.682Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":3723,"end":3854},{"type":"TextQuoteSelector","exact":"in fact this is so common that sheet music publishers willsometimes arrange music so that page turns land at a more convenient time","prefix":"eirinstrument to turn the page, ","suffix":". Thewidespread digitisation of "}]}]}
>```
>%%
>*%%PREFIX%%eirinstrument to turn the page,%%HIGHLIGHT%% ==in fact this is so common that sheet music publishers willsometimes arrange music so that page turns land at a more convenient time== %%POSTFIX%%. Thewidespread digitisation of*
>%%LINK%%[[#^7i7h36vxa6y|show annotation]]
>%%COMMENT%%
>page turning is a long-time issue
>%%TAGS%%
>
^7i7h36vxa6y



>%%
>```annotation-json
>{"created":"2024-10-02T22:06:15.805Z","text":"problems of current digital music sheet applications","updated":"2024-10-02T22:06:15.805Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":799,"end":841},{"type":"TextQuoteSelector","exact":"tablet device could be placed horizontally","prefix":"aller in size thanan A4 page. A ","suffix":" which allows two pages to bedis"}]}]}
>```
>%%
>*%%PREFIX%%aller in size thanan A4 page. A%%HIGHLIGHT%% ==tablet device could be placed horizontally== %%POSTFIX%%which allows two pages to bedis*
>%%LINK%%[[#^dht3zhw7fd4|show annotation]]
>%%COMMENT%%
>problems of current digital music sheet applications
>%%TAGS%%
>
^dht3zhw7fd4


>%%
>```annotation-json
>{"created":"2024-10-02T22:09:27.569Z","updated":"2024-10-02T22:09:27.569Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":5107,"end":5260},{"type":"TextQuoteSelector","exact":"to create an automatic page turner there must be a system whichkeeps track of the musicians place in the sheet music and appropriately triggers pageturns","prefix":"n in howpage turns are handled, ","suffix":". This dissertation will explore"}]}]}
>```
>%%
>*%%PREFIX%%n in howpage turns are handled,%%HIGHLIGHT%% ==to create an automatic page turner there must be a system whichkeeps track of the musicians place in the sheet music and appropriately triggers pageturns== %%POSTFIX%%. This dissertation will explore*
>%%LINK%%[[#^bifj12qw5i|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bifj12qw5i


>%%
>```annotation-json
>{"created":"2024-10-02T22:10:56.594Z","updated":"2024-10-02T22:10:56.594Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":5887,"end":5898},{"type":"TextQuoteSelector","exact":"distraction","prefix":" of turning pages can also be a ","suffix":" for musicians. Therehave been s"}]}]}
>```
>%%
>*%%PREFIX%%of turning pages can also be a%%HIGHLIGHT%% ==distraction== %%POSTFIX%%for musicians. Therehave been s*
>%%LINK%%[[#^2bjg7vd1geb|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2bjg7vd1geb


>%%
>```annotation-json
>{"created":"2024-10-02T22:11:25.646Z","text":"current solutions of semi-automatic page-turning all must be manually triggered","updated":"2024-10-02T22:11:25.646Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":6096,"end":6114},{"type":"TextQuoteSelector","exact":"manually triggered","prefix":"e in common is that theymust be ","suffix":". One of the key focuses for thi"}]}]}
>```
>%%
>*%%PREFIX%%e in common is that theymust be%%HIGHLIGHT%% ==manually triggered== %%POSTFIX%%. One of the key focuses for thi*
>%%LINK%%[[#^59e0g68q49x|show annotation]]
>%%COMMENT%%
>current solutions of semi-automatic page-turning all must be manually triggered
>%%TAGS%%
>
^59e0g68q49x


>%%
>```annotation-json
>{"created":"2024-10-02T22:16:25.408Z","text":"One Key focus","updated":"2024-10-02T22:16:25.408Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":6116,"end":6299},{"type":"TextQuoteSelector","exact":"One of the key focuses for this project was to design a passiveinterface which involved minimal active interactions from the user, thus minimising thedistraction caused by page turns.","prefix":"theymust be manually triggered. ","suffix":" There are various possibilities"}]}]}
>```
>%%
>*%%PREFIX%%theymust be manually triggered.%%HIGHLIGHT%% ==One of the key focuses for this project was to design a passiveinterface which involved minimal active interactions from the user, thus minimising thedistraction caused by page turns.== %%POSTFIX%%There are various possibilities*
>%%LINK%%[[#^c7vjdoly5dw|show annotation]]
>%%COMMENT%%
>One Key focus
>%%TAGS%%
>
^c7vjdoly5dw


>%%
>```annotation-json
>{"created":"2024-10-02T22:18:03.807Z","text":"two mechanism involved in a auto turning pages system","updated":"2024-10-02T22:18:03.807Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":6386,"end":6478},{"type":"TextQuoteSelector","exact":"mechanism for displaying new music on-screen as wellas the system to trigger such page turns","prefix":"-turning interface; both in the ","suffix":". Gaze detection was chosen as t"}]}]}
>```
>%%
>*%%PREFIX%%-turning interface; both in the%%HIGHLIGHT%% ==mechanism for displaying new music on-screen as wellas the system to trigger such page turns== %%POSTFIX%%. Gaze detection was chosen as t*
>%%LINK%%[[#^bzwap29q3d8|show annotation]]
>%%COMMENT%%
>two mechanism involved in a auto turning pages system
>%%TAGS%%
>
^bzwap29q3d8


>%%
>```annotation-json
>{"created":"2024-10-02T22:37:29.269Z","text":"The journal uses a high-end research-grade device(SMI RED500 eye-gaze tracker) to evaluate the Kalman filter model with real eye-gaze data, rather than a widely accessible commercial product for general consumer use","updated":"2024-10-02T22:37:29.269Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":6702,"end":6949},{"type":"TextQuoteSelector","exact":"Although there has already been research focused on using gaze detection toturn the pages of sheet music (Tabone et al., 2020), the use of gaze detection performedwith commercial hardware in a general setting has not been studied for this use case","prefix":" page-turning from themusician. ","suffix":". Assuch, this dissertation aims"}]}]}
>```
>%%
>*%%PREFIX%%page-turning from themusician.%%HIGHLIGHT%% ==Although there has already been research focused on using gaze detection toturn the pages of sheet music (Tabone et al., 2020), the use of gaze detection performedwith commercial hardware in a general setting has not been studied for this use case== %%POSTFIX%%. Assuch, this dissertation aims*
>%%LINK%%[[#^s1xf37263zf|show annotation]]
>%%COMMENT%%
>The journal uses a high-end research-grade device(SMI RED500 eye-gaze tracker) to evaluate the Kalman filter model with real eye-gaze data, rather than a widely accessible commercial product for general consumer use
>%%TAGS%%
>
^s1xf37263zf


>%%
>```annotation-json
>{"created":"2024-10-02T22:48:40.347Z","updated":"2024-10-02T22:48:40.347Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":7317,"end":7394},{"type":"TextQuoteSelector","exact":" evaluating gaze detection as a trigger mechanism forsheet music page-turning","prefix":"wThis dissertation will focus on","suffix":", as well as comparing between d"}]}]}
>```
>%%
>*%%PREFIX%%wThis dissertation will focus on%%HIGHLIGHT%% ==evaluating gaze detection as a trigger mechanism forsheet music page-turning== %%POSTFIX%%, as well as comparing between d*
>%%LINK%%[[#^wthai01npui|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wthai01npui


>%%
>```annotation-json
>{"created":"2024-10-02T22:48:48.137Z","updated":"2024-10-02T22:48:48.137Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":7407,"end":7455},{"type":"TextQuoteSelector","exact":"comparing between different page-turning systems","prefix":" music page-turning, as well as ","suffix":".An application will be develope"}]}]}
>```
>%%
>*%%PREFIX%%music page-turning, as well as%%HIGHLIGHT%% ==comparing between different page-turning systems== %%POSTFIX%%.An application will be develope*
>%%LINK%%[[#^3thdsy87zxr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3thdsy87zxr


>%%
>```annotation-json
>{"created":"2024-10-02T22:51:35.076Z","updated":"2024-10-02T22:51:35.076Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":9593,"end":9685},{"type":"TextQuoteSelector","exact":"This animation isquite important as it gives the user an indication that the page is turning","prefix":"brings the next page into view. ","suffix":", helping userskeep track of whe"}]}]}
>```
>%%
>*%%PREFIX%%brings the next page into view.%%HIGHLIGHT%% ==This animation isquite important as it gives the user an indication that the page is turning== %%POSTFIX%%, helping userskeep track of whe*
>%%LINK%%[[#^06djid35ohk3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^06djid35ohk3


>%%
>```annotation-json
>{"created":"2024-10-02T22:53:49.352Z","updated":"2024-10-02T22:53:49.352Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":9926,"end":9977},{"type":"TextQuoteSelector","exact":" using real-time audio of a performance as a trigge","prefix":"v, 2007).Research in the area of","suffix":"r forpage-turning focused on ali"}]}]}
>```
>%%
>*%%PREFIX%%v, 2007).Research in the area of%%HIGHLIGHT%% ==using real-time audio of a performance as a trigge== %%POSTFIX%%r forpage-turning focused on ali*
>%%LINK%%[[#^hnk2ak67gf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hnk2ak67gf


>%%
>```annotation-json
>{"created":"2024-10-02T23:29:33.391Z","updated":"2024-10-02T23:29:33.391Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":10006,"end":10213},{"type":"TextQuoteSelector","exact":"aligning the audio of a live performance with that of asynthesised audio file of the piece the musician is playing (Arzt et al., 2008). By aligning thetwo audio files, an estimate of the musicianʼs progress ","prefix":"gger forpage-turning focused on ","suffix":"through the piece could becalcul"}]}]}
>```
>%%
>*%%PREFIX%%gger forpage-turning focused on%%HIGHLIGHT%% ==aligning the audio of a live performance with that of asynthesised audio file of the piece the musician is playing (Arzt et al., 2008). By aligning thetwo audio files, an estimate of the musicianʼs progress== %%POSTFIX%%through the piece could becalcul*
>%%LINK%%[[#^bhg7l5ej5v6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bhg7l5ej5v6


>%%
>```annotation-json
>{"created":"2024-10-02T23:29:55.265Z","updated":"2024-10-02T23:29:55.265Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":10324,"end":10448},{"type":"TextQuoteSelector","exact":"gaze-detection as a trigger for page turns, using aninfrared-based eye tracking device: the SMI RED500 (Tabone et al., 2020)","prefix":"rns.A recent study investigated ","suffix":". Kalman filteringwas used to sm"}]}]}
>```
>%%
>*%%PREFIX%%rns.A recent study investigated%%HIGHLIGHT%% ==gaze-detection as a trigger for page turns, using aninfrared-based eye tracking device: the SMI RED500 (Tabone et al., 2020)== %%POSTFIX%%. Kalman filteringwas used to sm*
>%%LINK%%[[#^x1q9f0dcv2j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^x1q9f0dcv2j


>%%
>```annotation-json
>{"created":"2024-10-02T23:32:03.974Z","updated":"2024-10-02T23:32:03.974Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":10978,"end":11075},{"type":"TextQuoteSelector","exact":"the goal of gaze detection or eye tracking is to understand where a subject islooking in 3D space","prefix":" et al., 1950). Broadlyspeaking ","suffix":". There are a number of differen"}]}]}
>```
>%%
>*%%PREFIX%%et al., 1950). Broadlyspeaking%%HIGHLIGHT%% ==the goal of gaze detection or eye tracking is to understand where a subject islooking in 3D space== %%POSTFIX%%. There are a number of differen*
>%%LINK%%[[#^ayhd7w9fp7q|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ayhd7w9fp7q


>%%
>```annotation-json
>{"created":"2024-10-02T23:40:51.604Z","updated":"2024-10-02T23:40:51.604Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":11159,"end":11168},{"type":"TextQuoteSelector","exact":"intrusive","prefix":" problem, some ofwhich are more ","suffix":" than others. One of the less co"}]}]}
>```
>%%
>*%%PREFIX%%problem, some ofwhich are more%%HIGHLIGHT%% ==intrusive== %%POSTFIX%%than others. One of the less co*
>%%LINK%%[[#^t7wphitx8rk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^t7wphitx8rk


>%%
>```annotation-json
>{"created":"2024-10-02T23:45:42.678Z","text":"笨重","updated":"2024-10-02T23:45:42.678Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":12607,"end":12617},{"type":"TextQuoteSelector","exact":"cumbersome","prefix":"ystems were originally largeand ","suffix":", but have been miniaturised and"}]}]}
>```
>%%
>*%%PREFIX%%ystems were originally largeand%%HIGHLIGHT%% ==cumbersome== %%POSTFIX%%, but have been miniaturised and*
>%%LINK%%[[#^lku5uvd4f8a|show annotation]]
>%%COMMENT%%
>笨重
>%%TAGS%%
>
^lku5uvd4f8a


>%%
>```annotation-json
>{"created":"2024-10-02T23:45:52.266Z","text":"微型化","updated":"2024-10-02T23:45:52.266Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":12633,"end":12645},{"type":"TextQuoteSelector","exact":"miniaturised","prefix":"geand cumbersome, but have been ","suffix":" and stylised with time. Some ex"}]}]}
>```
>%%
>*%%PREFIX%%geand cumbersome, but have been%%HIGHLIGHT%% ==miniaturised== %%POSTFIX%%and stylised with time. Some ex*
>%%LINK%%[[#^rpbwxvo0uf|show annotation]]
>%%COMMENT%%
>微型化
>%%TAGS%%
>
^rpbwxvo0uf


>%%
>```annotation-json
>{"created":"2024-10-02T23:46:10.109Z","text":"环境光","updated":"2024-10-02T23:46:10.109Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":12782,"end":12795},{"type":"TextQuoteSelector","exact":"ambient light","prefix":"nted systems use infraredlight: ","suffix":" is also used, as is the case wi"}]}]}
>```
>%%
>*%%PREFIX%%nted systems use infraredlight:%%HIGHLIGHT%% ==ambient light== %%POSTFIX%%is also used, as is the case wi*
>%%LINK%%[[#^o9xgtgow2k8|show annotation]]
>%%COMMENT%%
>环境光
>%%TAGS%%
>
^o9xgtgow2k8


>%%
>```annotation-json
>{"created":"2024-10-02T23:47:18.371Z","updated":"2024-10-02T23:47:18.371Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":13073,"end":13305},{"type":"TextQuoteSelector","exact":"The remaining eye tracking systems are less intrusive but still rely on videoanalysis. These remaining systems can be broken down into three main categories:● Infrared-based systems● Geometric-based systems● Appearance-based systems","prefix":"to determine the gaze direction.","suffix":"There are non-head-mounted eye t"}]}]}
>```
>%%
>*%%PREFIX%%to determine the gaze direction.%%HIGHLIGHT%% ==The remaining eye tracking systems are less intrusive but still rely on videoanalysis. These remaining systems can be broken down into three main categories:● Infrared-based systems● Geometric-based systems● Appearance-based systems== %%POSTFIX%%There are non-head-mounted eye t*
>%%LINK%%[[#^5lucpfn0f5k|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5lucpfn0f5k


>%%
>```annotation-json
>{"created":"2024-10-02T23:48:13.018Z","updated":"2024-10-02T23:48:13.018Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":13528,"end":13579},{"type":"TextQuoteSelector","exact":"Geometric-based systems build a 3D model of the eye","prefix":"stems can be seen in Figure 2.1.","suffix":" and use geometric reasoningto e"}]}]}
>```
>%%
>*%%PREFIX%%stems can be seen in Figure 2.1.%%HIGHLIGHT%% ==Geometric-based systems build a 3D model of the eye== %%POSTFIX%%and use geometric reasoningto e*
>%%LINK%%[[#^jmxrp60pbpn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jmxrp60pbpn


>%%
>```annotation-json
>{"created":"2024-10-02T23:48:28.874Z","updated":"2024-10-02T23:48:28.874Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":13699,"end":13813},{"type":"TextQuoteSelector","exact":" identify a subjectʼs face within an image and then features such as the eye contour andpupil location are detecte","prefix":"013). Facial detection is usedto","suffix":"d. These features are used to bu"}]}]}
>```
>%%
>*%%PREFIX%%013). Facial detection is usedto%%HIGHLIGHT%% ==identify a subjectʼs face within an image and then features such as the eye contour andpupil location are detecte== %%POSTFIX%%d. These features are used to bu*
>%%LINK%%[[#^8wh4396grtx|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8wh4396grtx


>%%
>```annotation-json
>{"created":"2024-10-02T23:49:01.700Z","updated":"2024-10-02T23:49:01.700Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":13885,"end":14021},{"type":"TextQuoteSelector","exact":"subjectʼs head pose must also be identified, as the combination of the head poseand pupil directions are used to calculate a gaze vector","prefix":" model of a subject ʻseyes. The ","suffix":". These techniques use depthsens"}]}]}
>```
>%%
>*%%PREFIX%%model of a subject ʻseyes. The%%HIGHLIGHT%% ==subjectʼs head pose must also be identified, as the combination of the head poseand pupil directions are used to calculate a gaze vector== %%POSTFIX%%. These techniques use depthsens*
>%%LINK%%[[#^jesoaslwq3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jesoaslwq3


>%%
>```annotation-json
>{"created":"2024-10-02T23:51:31.333Z","updated":"2024-10-02T23:51:31.333Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":13443,"end":13453},{"type":"TextQuoteSelector","exact":"reflection","prefix":"based on the same principles of ","suffix":" from the eye. Anexample of one "}]}]}
>```
>%%
>*%%PREFIX%%based on the same principles of%%HIGHLIGHT%% ==reflection== %%POSTFIX%%from the eye. Anexample of one*
>%%LINK%%[[#^3yppqpk8p6v|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3yppqpk8p6v


>%%
>```annotation-json
>{"created":"2024-10-02T23:51:37.815Z","updated":"2024-10-02T23:51:37.815Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":14546,"end":14589},{"type":"TextQuoteSelector","exact":"Appearance-based systems use ambient light ","prefix":"cation of the subjectʼs pupils.8","suffix":"and standard video of a subject."}]}]}
>```
>%%
>*%%PREFIX%%cation of the subjectʼs pupils.8%%HIGHLIGHT%% ==Appearance-based systems use ambient light== %%POSTFIX%%and standard video of a subject.*
>%%LINK%%[[#^c3hwbu2ueju|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^c3hwbu2ueju


>%%
>```annotation-json
>{"created":"2024-10-03T00:07:49.703Z","text":"视点","updated":"2024-10-03T00:07:49.703Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":14998,"end":15014},{"type":"TextQuoteSelector","exact":"points of regard","prefix":"n eye within animage with known ","suffix":". This allows for the creation o"}]}]}
>```
>%%
>*%%PREFIX%%n eye within animage with known%%HIGHLIGHT%% ==points of regard== %%POSTFIX%%. This allows for the creation o*
>%%LINK%%[[#^z5wjm6aqu7|show annotation]]
>%%COMMENT%%
>视点
>%%TAGS%%
>
^z5wjm6aqu7


>%%
>```annotation-json
>{"created":"2024-10-03T12:39:43.014Z","text":"crop, unlike patch(a square small piece), crop refer to a meaningful section/feature out of an image like eye, iris","updated":"2024-10-03T12:39:43.014Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":15730,"end":15736},{"type":"TextQuoteSelector","exact":"crops ","prefix":" a deep-learning approach, where","suffix":"of a subject's eyes were used as"}]}]}
>```
>%%
>*%%PREFIX%%a deep-learning approach, where%%HIGHLIGHT%% ==crops== %%POSTFIX%%of a subject's eyes were used as*
>%%LINK%%[[#^n6qdf3qek0q|show annotation]]
>%%COMMENT%%
>crop, unlike patch(a square small piece), crop refer to a meaningful section/feature out of an image like eye, iris
>%%TAGS%%
>
^n6qdf3qek0q


>%%
>```annotation-json
>{"created":"2024-10-03T12:43:30.723Z","text":"calibration 校准","updated":"2024-10-03T12:43:30.723Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":16354,"end":16405},{"type":"TextQuoteSelector","exact":"iTracker doesnʼt require person-specificcalibration","prefix":"tʼs face in the original image. ","suffix":", although it was shown in the 2"}]}]}
>```
>%%
>*%%PREFIX%%tʼs face in the original image.%%HIGHLIGHT%% ==iTracker doesnʼt require person-specificcalibration== %%POSTFIX%%, although it was shown in the 2*
>%%LINK%%[[#^n1ae5klmp7|show annotation]]
>%%COMMENT%%
>calibration 校准
>%%TAGS%%
>
^n1ae5klmp7


>%%
>```annotation-json
>{"created":"2024-10-03T12:44:21.794Z","updated":"2024-10-03T12:44:21.794Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":14621,"end":14757},{"type":"TextQuoteSelector","exact":"Facial-detection techniques are used to isolate a face crop from an image of a subject,then features are extracted from this face image.","prefix":"and standard video of a subject.","suffix":" Examples of these features are "}]}]}
>```
>%%
>*%%PREFIX%%and standard video of a subject.%%HIGHLIGHT%% ==Facial-detection techniques are used to isolate a face crop from an image of a subject,then features are extracted from this face image.== %%POSTFIX%%Examples of these features are*
>%%LINK%%[[#^aikbu6dhiac|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^aikbu6dhiac


>%%
>```annotation-json
>{"created":"2024-10-03T12:44:52.175Z","updated":"2024-10-03T12:44:52.175Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":16740,"end":16794},{"type":"TextQuoteSelector","exact":"they require segmentation of faces and eyes fromimages","prefix":"timation have in common is that ","suffix":". There are several approaches t"}]}]}
>```
>%%
>*%%PREFIX%%timation have in common is that%%HIGHLIGHT%% ==they require segmentation of faces and eyes fromimages== %%POSTFIX%%. There are several approaches t*
>%%LINK%%[[#^tqsfndz43n|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tqsfndz43n


>%%
>```annotation-json
>{"created":"2024-10-03T12:46:00.391Z","text":"IOS playform, itracker and seeso to detect gaze, output of them as trigger of 3 page turning animations.\nAdditional calibration function to both calculate the metrics on the gaze systems and compensate for errors by the gaze detection systems","updated":"2024-10-03T12:46:00.391Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":17345,"end":17380},{"type":"TextQuoteSelector","exact":"EyeGaze app architecture and design","prefix":"velopment of the EyeGaze app3.1 ","suffix":"There were a number of important"}]}]}
>```
>%%
>*%%PREFIX%%velopment of the EyeGaze app3.1%%HIGHLIGHT%% ==EyeGaze app architecture and design== %%POSTFIX%%There were a number of important*
>%%LINK%%[[#^votiv2fem7n|show annotation]]
>%%COMMENT%%
>IOS playform, itracker and seeso to detect gaze, output of them as trigger of 3 page turning animations.
>Additional calibration function to both calculate the metrics on the gaze systems and compensate for errors by the gaze detection systems
>%%TAGS%%
>
^votiv2fem7n


>%%
>```annotation-json
>{"created":"2024-10-03T12:55:37.895Z","updated":"2024-10-03T12:55:37.895Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":19322,"end":19482},{"type":"TextQuoteSelector","exact":"The calibration process allows for gaze estimations to be comparedwith known ground truth values, since the locations of the calibration dots arepre-determined.","prefix":"n allows forseveral advantages. ","suffix":" With the assumption that the us"}]}]}
>```
>%%
>*%%PREFIX%%n allows forseveral advantages.%%HIGHLIGHT%% ==The calibration process allows for gaze estimations to be comparedwith known ground truth values, since the locations of the calibration dots arepre-determined.== %%POSTFIX%%With the assumption that the us*
>%%LINK%%[[#^gwkl0wn2zmj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gwkl0wn2zmj


>%%
>```annotation-json
>{"created":"2024-10-03T12:59:28.342Z","updated":"2024-10-03T12:59:28.342Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":19633,"end":19674},{"type":"TextQuoteSelector","exact":"metrics are calculated on the performance","prefix":"ared to the actual locations and","suffix":" of the gaze detection system. C"}]}]}
>```
>%%
>*%%PREFIX%%ared to the actual locations and%%HIGHLIGHT%% ==metrics are calculated on the performance== %%POSTFIX%%of the gaze detection system. C*
>%%LINK%%[[#^jtrsk2ser1k|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jtrsk2ser1k


>%%
>```annotation-json
>{"created":"2024-10-03T12:59:38.824Z","updated":"2024-10-03T12:59:38.824Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":19908,"end":19978},{"type":"TextQuoteSelector","exact":"calibration results can be used to fine-tune the page-turningtechnique","prefix":" calibrationprocess is that the ","suffix":"s. To give an example, if the ga"}]}]}
>```
>%%
>*%%PREFIX%%calibrationprocess is that the%%HIGHLIGHT%% ==calibration results can be used to fine-tune the page-turningtechnique== %%POSTFIX%%s. To give an example, if the ga*
>%%LINK%%[[#^3gf7981fn9b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3gf7981fn9b


>%%
>```annotation-json
>{"created":"2024-10-03T13:04:08.800Z","updated":"2024-10-03T13:04:08.800Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":20705,"end":20796},{"type":"TextQuoteSelector","exact":"SeeSooperates directly on a camera feed, whereas iTracker has specific inputs which must be","prefix":"redictions (Visual Camp, 2021). ","suffix":"12prepared before any gaze predi"}]}]}
>```
>%%
>*%%PREFIX%%redictions (Visual Camp, 2021).%%HIGHLIGHT%% ==SeeSooperates directly on a camera feed, whereas iTracker has specific inputs which must be== %%POSTFIX%%12prepared before any gaze predi*
>%%LINK%%[[#^3z0b36b02t7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3z0b36b02t7


>%%
>```annotation-json
>{"created":"2024-10-03T13:04:16.416Z","updated":"2024-10-03T13:04:16.416Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":20798,"end":20849},{"type":"TextQuoteSelector","exact":"prepared before any gaze predictions are performed.","prefix":" specific inputs which must be12","suffix":" To transform the front-facing c"}]}]}
>```
>%%
>*%%PREFIX%%specific inputs which must be12%%HIGHLIGHT%% ==prepared before any gaze predictions are performed.== %%POSTFIX%%To transform the front-facing c*
>%%LINK%%[[#^k6b0rhckjth|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^k6b0rhckjth


>%%
>```annotation-json
>{"created":"2024-10-03T13:04:38.225Z","updated":"2024-10-03T13:04:38.225Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":20918,"end":20978},{"type":"TextQuoteSelector","exact":"iTracker, a face and eye segmentation module wasimplemented.","prefix":"frames into suitable inputs for ","suffix":" Although the SeeSo SDK provides"}]}]}
>```
>%%
>*%%PREFIX%%frames into suitable inputs for%%HIGHLIGHT%% ==iTracker, a face and eye segmentation module wasimplemented.== %%POSTFIX%%Although the SeeSo SDK provides*
>%%LINK%%[[#^t9t71dcqr48|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^t9t71dcqr48


>%%
>```annotation-json
>{"created":"2024-10-03T13:09:28.285Z","updated":"2024-10-03T13:09:28.285Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":23686,"end":23842},{"type":"TextQuoteSelector","exact":"the first of which progresses from the top ofthe screen to halfway down the screen, peeling away the current page to reveal the nextpage of music underneath","prefix":"urn consists of two animations, ","suffix":". Once it is identified that the"}]}]}
>```
>%%
>*%%PREFIX%%urn consists of two animations,%%HIGHLIGHT%% ==the first of which progresses from the top ofthe screen to halfway down the screen, peeling away the current page to reveal the nextpage of music underneath== %%POSTFIX%%. Once it is identified that the*
>%%LINK%%[[#^246t36y4vao|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^246t36y4vao


>%%
>```annotation-json
>{"created":"2024-10-03T13:09:43.136Z","updated":"2024-10-03T13:09:43.136Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":24003,"end":24139},{"type":"TextQuoteSelector","exact":"This second animation continues where the first finished, scrolling down to thebottom of the screen, revealing the rest of the next page","prefix":"e second animation istriggered. ","suffix":". Figure 3.4 depicts the various"}]}]}
>```
>%%
>*%%PREFIX%%e second animation istriggered.%%HIGHLIGHT%% ==This second animation continues where the first finished, scrolling down to thebottom of the screen, revealing the rest of the next page== %%POSTFIX%%. Figure 3.4 depicts the various*
>%%LINK%%[[#^iiohwrgeax|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^iiohwrgeax


>%%
>```annotation-json
>{"created":"2024-10-03T13:11:14.719Z","updated":"2024-10-03T13:11:14.719Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":25611,"end":25709},{"type":"TextQuoteSelector","exact":"Each dot was displayed until 30 frames were capturedwhere valid gaze detection could be performed.","prefix":"y one dot is visible at a time. ","suffix":" If no face was detected from th"}]}]}
>```
>%%
>*%%PREFIX%%y one dot is visible at a time.%%HIGHLIGHT%% ==Each dot was displayed until 30 frames were capturedwhere valid gaze detection could be performed.== %%POSTFIX%%If no face was detected from th*
>%%LINK%%[[#^s6ru6cz6ta|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^s6ru6cz6ta


>%%
>```annotation-json
>{"created":"2024-10-03T13:35:18.651Z","updated":"2024-10-03T13:35:18.651Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":26593,"end":26696},{"type":"TextQuoteSelector","exact":"first to identify if there were any faces present in the frame, using the Visionframework (Apple, 2017)","prefix":"landmark detection wasperformed ","suffix":". If no faces are detected in th"}]}]}
>```
>%%
>*%%PREFIX%%landmark detection wasperformed%%HIGHLIGHT%% ==first to identify if there were any faces present in the frame, using the Visionframework (Apple, 2017)== %%POSTFIX%%. If no faces are detected in th*
>%%LINK%%[[#^p0oc50dfzz|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^p0oc50dfzz


>%%
>```annotation-json
>{"created":"2024-10-03T13:41:52.257Z","updated":"2024-10-03T13:41:52.257Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":29384,"end":29546},{"type":"TextQuoteSelector","exact":"anapproach was taken such that gaze predictions which were outside the screen bounds butwithin a close range to the screen were clamped to the edges of the screen","prefix":"nd SeeSo gaze detection systems ","suffix":".3.2.4 Implementation of scrolli"}]}]}
>```
>%%
>*%%PREFIX%%nd SeeSo gaze detection systems%%HIGHLIGHT%% ==anapproach was taken such that gaze predictions which were outside the screen bounds butwithin a close range to the screen were clamped to the edges of the screen== %%POSTFIX%%.3.2.4 Implementation of scrolli*
>%%LINK%%[[#^6vndnj0ysm7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6vndnj0ysm7


>%%
>```annotation-json
>{"created":"2024-10-03T13:42:00.559Z","updated":"2024-10-03T13:42:00.559Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":29036,"end":29301},{"type":"TextQuoteSelector","exact":"Usingscaling factors to scale the x and y components of the gaze predictions resulted in far moreaccurate predictions. These scaling factors were initialised to default values anddynamically updated to minimise the dot error as the calibration process was completed","prefix":"wards the centre of the screen. ","suffix":".18To help reduce the errors of "}]}]}
>```
>%%
>*%%PREFIX%%wards the centre of the screen.%%HIGHLIGHT%% ==Usingscaling factors to scale the x and y components of the gaze predictions resulted in far moreaccurate predictions. These scaling factors were initialised to default values anddynamically updated to minimise the dot error as the calibration process was completed== %%POSTFIX%%.18To help reduce the errors of*
>%%LINK%%[[#^3fiq9tpnv9n|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3fiq9tpnv9n


>%%
>```annotation-json
>{"created":"2024-10-03T13:42:35.024Z","updated":"2024-10-03T13:42:35.024Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":29683,"end":29731},{"type":"TextQuoteSelector","exact":"adapt the scrolling speed given gaze predictions","prefix":"as implementing thealgorithm to ","suffix":". The screen is conceptuallydivi"}]}]}
>```
>%%
>*%%PREFIX%%as implementing thealgorithm to%%HIGHLIGHT%% ==adapt the scrolling speed given gaze predictions== %%POSTFIX%%. The screen is conceptuallydivi*
>%%LINK%%[[#^pbr59bto5pc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^pbr59bto5pc


>%%
>```annotation-json
>{"created":"2024-10-03T13:43:14.284Z","updated":"2024-10-03T13:43:14.284Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":29952,"end":30090},{"type":"TextQuoteSelector","exact":"both gaze detection systems was found to be noisy, so a rollingaverage was taken of the userʼs gaze using the last fi\u0000een gaze predictions","prefix":"8. The gazeprediction data from ","suffix":". Using thisrolling average help"}]}]}
>```
>%%
>*%%PREFIX%%8. The gazeprediction data from%%HIGHLIGHT%% ==both gaze detection systems was found to be noisy, so a rollingaverage was taken of the userʼs gaze using the last fi een gaze predictions== %%POSTFIX%%. Using thisrolling average help*
>%%LINK%%[[#^dh1oea7xo74|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dh1oea7xo74


>%%
>```annotation-json
>{"created":"2024-10-03T13:45:22.386Z","updated":"2024-10-03T13:45:22.386Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":30251,"end":30345},{"type":"TextQuoteSelector","exact":"the scrolling speed is graduallyupdated until it reaches the correct speed for the new section","prefix":"ction of the screen to another, ","suffix":". This gradual update of thescro"}]}]}
>```
>%%
>*%%PREFIX%%ction of the screen to another,%%HIGHLIGHT%% ==the scrolling speed is graduallyupdated until it reaches the correct speed for the new section== %%POSTFIX%%. This gradual update of thescro*
>%%LINK%%[[#^682t3huuj0q|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^682t3huuj0q


>%%
>```annotation-json
>{"created":"2024-10-03T13:45:59.241Z","updated":"2024-10-03T13:45:59.241Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":30508,"end":30667},{"type":"TextQuoteSelector","exact":"scrolling is disabled and is only enabled once theuserʼs gaze has dropped below a threshold; in this case the threshold is a quarter of theheight of the screen","prefix":"n the PDF file is first opened, ","suffix":". This threshold is shown in Fig"}]}]}
>```
>%%
>*%%PREFIX%%n the PDF file is first opened,%%HIGHLIGHT%% ==scrolling is disabled and is only enabled once theuserʼs gaze has dropped below a threshold; in this case the threshold is a quarter of theheight of the screen== %%POSTFIX%%. This threshold is shown in Fig*
>%%LINK%%[[#^u4fdv8lo19l|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^u4fdv8lo19l


>%%
>```annotation-json
>{"created":"2024-10-03T13:46:36.022Z","updated":"2024-10-03T13:46:36.022Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":30981,"end":31236},{"type":"TextQuoteSelector","exact":"If no face is detected from the front-facing camera feed then no gazepredictions are supplied, and in this situation the scrolling speed remains constant, underthe assumption that the user is still playing the piece, but has simply glanced awaymomentarily","prefix":"ser looking awayfrom the music. ","suffix":".3.2.5 Implementation of single "}]}]}
>```
>%%
>*%%PREFIX%%ser looking awayfrom the music.%%HIGHLIGHT%% ==If no face is detected from the front-facing camera feed then no gazepredictions are supplied, and in this situation the scrolling speed remains constant, underthe assumption that the user is still playing the piece, but has simply glanced awaymomentarily== %%POSTFIX%%.3.2.5 Implementation of single*
>%%LINK%%[[#^33yog09hel5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^33yog09hel5


>%%
>```annotation-json
>{"created":"2024-10-03T13:47:10.474Z","updated":"2024-10-03T13:47:10.474Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":31550,"end":31562},{"type":"TextQuoteSelector","exact":"bottom right","prefix":"ge enters a bounding box in the ","suffix":"19corner of the screen a timer i"}]}]}
>```
>%%
>*%%PREFIX%%ge enters a bounding box in the%%HIGHLIGHT%% ==bottom right== %%POSTFIX%%19corner of the screen a timer i*
>%%LINK%%[[#^a6bj610vm8n|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^a6bj610vm8n


>%%
>```annotation-json
>{"created":"2024-10-03T13:47:44.290Z","updated":"2024-10-03T13:47:44.290Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":31672,"end":31816},{"type":"TextQuoteSelector","exact":" A timer is used as a rough prediction of the length of time it willtake the user to finish reading the music contained within the bounding box.","prefix":"page turnanimation is triggered.","suffix":" The areawhich defines this boun"}]}]}
>```
>%%
>*%%PREFIX%%page turnanimation is triggered.%%HIGHLIGHT%% ==A timer is used as a rough prediction of the length of time it willtake the user to finish reading the music contained within the bounding box.== %%POSTFIX%%The areawhich defines this boun*
>%%LINK%%[[#^xjmvdfchauf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xjmvdfchauf


>%%
>```annotation-json
>{"created":"2024-10-03T13:48:26.041Z","updated":"2024-10-03T13:48:26.041Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":32153,"end":32331},{"type":"TextQuoteSelector","exact":"Once a page turn has beentriggered, there is a delay before another page turn can be triggered, to avoid a situationwhere several pages are turned in quick succession by accident","prefix":" using this as an anchor point. ","suffix":".Figure 3.8: Various scrolling s"}]}]}
>```
>%%
>*%%PREFIX%%using this as an anchor point.%%HIGHLIGHT%% ==Once a page turn has beentriggered, there is a delay before another page turn can be triggered, to avoid a situationwhere several pages are turned in quick succession by accident== %%POSTFIX%%.Figure 3.8: Various scrolling s*
>%%LINK%%[[#^rjmnkl0xgfm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rjmnkl0xgfm


>%%
>```annotation-json
>{"created":"2024-10-03T13:51:13.764Z","updated":"2024-10-03T13:51:13.764Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":34353,"end":34390},{"type":"TextQuoteSelector","exact":"Evaluation of the EyeGaze application","prefix":"bounding boxes to be larger.214 ","suffix":"4.1 Evaluation approachWhen desi"}]}]}
>```
>%%
>*%%PREFIX%%bounding boxes to be larger.214%%HIGHLIGHT%% ==Evaluation of the EyeGaze application== %%POSTFIX%%4.1 Evaluation approachWhen desi*
>%%LINK%%[[#^4e2kp38xn7o|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4e2kp38xn7o


>%%
>```annotation-json
>{"created":"2024-10-03T13:51:21.285Z","updated":"2024-10-03T13:51:21.285Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":34577,"end":34596},{"type":"TextQuoteSelector","exact":"real-world scenario","prefix":"ly applied to this use case ina ","suffix":". To effectively evaluate this, "}]}]}
>```
>%%
>*%%PREFIX%%ly applied to this use case ina%%HIGHLIGHT%% ==real-world scenario== %%POSTFIX%%. To effectively evaluate this,*
>%%LINK%%[[#^tnp1hprblx|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tnp1hprblx


>%%
>```annotation-json
>{"created":"2024-10-03T14:12:30.387Z","updated":"2024-10-03T14:12:30.387Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":34905,"end":35139},{"type":"TextQuoteSelector","exact":"There were severaldifferent aspects of the application to evaluate: the effectiveness of the page-turningsystems, user preference between the various page-turning systems and the performanceof the two different gaze detection systems.","prefix":"users had with the application. ","suffix":" A page-turning system can be co"}]}]}
>```
>%%
>*%%PREFIX%%users had with the application.%%HIGHLIGHT%% ==There were severaldifferent aspects of the application to evaluate: the effectiveness of the page-turningsystems, user preference between the various page-turning systems and the performanceof the two different gaze detection systems.== %%POSTFIX%%A page-turning system can be co*
>%%LINK%%[[#^83cjgo3dcvu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^83cjgo3dcvu


>%%
>```annotation-json
>{"created":"2024-10-03T14:18:44.592Z","updated":"2024-10-03T14:18:44.592Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":36607,"end":36694},{"type":"TextQuoteSelector","exact":"Each subject selected their own piece of music and played through their piece sixtimes;","prefix":"rease in gaze detectionaccuracy.","suffix":" using each of the three page-tu"}]}]}
>```
>%%
>*%%PREFIX%%rease in gaze detectionaccuracy.%%HIGHLIGHT%% ==Each subject selected their own piece of music and played through their piece sixtimes;== %%POSTFIX%%using each of the three page-tu*
>%%LINK%%[[#^2wzkv440ni4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2wzkv440ni4


>%%
>```annotation-json
>{"created":"2024-10-03T14:19:30.361Z","updated":"2024-10-03T14:19:30.361Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":37434,"end":37516},{"type":"TextQuoteSelector","exact":" collect data on whether eachpage turn happened early, late or at the correct time","prefix":"sent during the user study would","suffix":".4.1.2 MetricsMeasuring whether "}]}]}
>```
>%%
>*%%PREFIX%%sent during the user study would%%HIGHLIGHT%% ==collect data on whether eachpage turn happened early, late or at the correct time== %%POSTFIX%%.4.1.2 MetricsMeasuring whether*
>%%LINK%%[[#^tnbfj0mztzo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tnbfj0mztzo


>%%
>```annotation-json
>{"created":"2024-10-03T14:20:31.572Z","updated":"2024-10-03T14:20:31.572Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":37530,"end":37701},{"type":"TextQuoteSelector","exact":"Measuring whether page turns were early, late or at the correct time was suitablefor the single and double animation page-turning systems, but not for the scrolling system","prefix":"t the correct time.4.1.2 Metrics","suffix":".In order to record a similar me"}]}]}
>```
>%%
>*%%PREFIX%%t the correct time.4.1.2 Metrics%%HIGHLIGHT%% ==Measuring whether page turns were early, late or at the correct time was suitablefor the single and double animation page-turning systems, but not for the scrolling system== %%POSTFIX%%.In order to record a similar me*
>%%LINK%%[[#^7t5r624ibej|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7t5r624ibej


>%%
>```annotation-json
>{"created":"2024-10-03T14:20:49.935Z","updated":"2024-10-03T14:20:49.935Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":37824,"end":38235},{"type":"TextQuoteSelector","exact":"If the system was scrolling too fast then the music beingplayed would be scrolled off-screen from the top of the screen, leading to the user havingto skip ahead in the piece. Similarly if the system was scrolling too slowly then the userwould reach the bottom of the screen before more music was scrolled on-screen from thebottom, causing a pause in the music as they waited for the scrolling system to catch up","prefix":"aps in the music were recorded. ","suffix":".Although the performance of gaz"}]}]}
>```
>%%
>*%%PREFIX%%aps in the music were recorded.%%HIGHLIGHT%% ==If the system was scrolling too fast then the music beingplayed would be scrolled off-screen from the top of the screen, leading to the user havingto skip ahead in the piece. Similarly if the system was scrolling too slowly then the userwould reach the bottom of the screen before more music was scrolled on-screen from thebottom, causing a pause in the music as they waited for the scrolling system to catch up== %%POSTFIX%%.Although the performance of gaz*
>%%LINK%%[[#^249oo1aceq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^249oo1aceq


>%%
>```annotation-json
>{"created":"2024-10-03T14:21:33.242Z","updated":"2024-10-03T14:21:33.242Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":38620,"end":38811},{"type":"TextQuoteSelector","exact":"The arithmetic mean of the distances incentimetres from each of these gaze estimation points to the respective ground truthpoints gives an indication of the error of the gaze detection system","prefix":"d for each dot shown on-screen. ","suffix":". If each individual gaze23estim"}]}]}
>```
>%%
>*%%PREFIX%%d for each dot shown on-screen.%%HIGHLIGHT%% ==The arithmetic mean of the distances incentimetres from each of these gaze estimation points to the respective ground truthpoints gives an indication of the error of the gaze detection system== %%POSTFIX%%. If each individual gaze23estim*
>%%LINK%%[[#^z20p2wwejj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^z20p2wwejj


>%%
>```annotation-json
>{"created":"2024-10-03T14:22:33.429Z","updated":"2024-10-03T14:22:33.429Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":39239,"end":39370},{"type":"TextQuoteSelector","exact":"The mean of the distances from all gaze𝑔𝑡 = (𝑔𝑡1 ,..., 𝑔𝑡10)estimations relevant to a particular calibration dot is given as:","prefix":"\udc61𝑝𝑌}calibration dots to be: . ","suffix":"𝑔𝑡𝑝𝑑𝑜𝑡𝑒𝑟𝑟𝑜𝑟𝑝 = 𝑚=13"}]}]}
>```
>%%
>*%%PREFIX%%�𝑝𝑌}calibration dots to be: .%%HIGHLIGHT%% ==The mean of the distances from all gaze𝑔𝑡 = (𝑔𝑡1 ,..., 𝑔𝑡10)estimations relevant to a particular calibration dot is given as:== %%POSTFIX%%𝑔𝑡𝑝𝑑𝑜𝑡𝑒𝑟𝑟𝑜𝑟𝑝 = 𝑚=13*
>%%LINK%%[[#^3ggxj0rbtk9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3ggxj0rbtk9



>%%
>```annotation-json
>{"created":"2024-10-03T14:22:53.236Z","updated":"2024-10-03T14:22:53.236Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":39473,"end":39519},{"type":"TextQuoteSelector","exact":"for the of all calibration dots to be given as","prefix":"\udc4c − 𝑒𝑠𝑡𝑝𝑚𝑌)230This allows ","suffix":":𝑑𝑜𝑡𝑒𝑟𝑟𝑜𝑟𝑑𝑜𝑡𝑒𝑟𝑟𝑜\ud835"}]}]}
>```
>%%
>*%%PREFIX%%� − 𝑒𝑠𝑡𝑝𝑚𝑌)230This allows%%HIGHLIGHT%% ==for the of all calibration dots to be given as== %%POSTFIX%%:𝑑𝑜𝑡𝑒𝑟𝑟𝑜𝑟𝑑𝑜𝑡𝑒𝑟𝑟𝑜�*
>%%LINK%%[[#^n04b73wzbbe|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^n04b73wzbbe


>%%
>```annotation-json
>{"created":"2024-10-03T14:23:30.826Z","updated":"2024-10-03T14:23:30.826Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":39811,"end":39991},{"type":"TextQuoteSelector","exact":"Another metric we will be using is thex axis skew, which will be the arithmetic mean of the x position distances from each gazeestimation point to the respective ground truth point","prefix":" metric (Kar & Corcoran, 2018). ","suffix":". Similarly we will use a y axis"}]}]}
>```
>%%
>*%%PREFIX%%metric (Kar & Corcoran, 2018).%%HIGHLIGHT%% ==Another metric we will be using is thex axis skew, which will be the arithmetic mean of the x position distances from each gazeestimation point to the respective ground truth point== %%POSTFIX%%. Similarly we will use a y axis*
>%%LINK%%[[#^2swnloce15h|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2swnloce15h


>%%
>```annotation-json
>{"created":"2024-10-03T14:23:47.744Z","updated":"2024-10-03T14:23:47.744Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":39700,"end":39762},{"type":"TextQuoteSelector","exact":" distance function is measured in centimetres instead ofpixels","prefix":"th the difference being that the","suffix":" for the doterror metric (Kar & "}]}]}
>```
>%%
>*%%PREFIX%%th the difference being that the%%HIGHLIGHT%% ==distance function is measured in centimetres instead ofpixels== %%POSTFIX%%for the doterror metric (Kar &*
>%%LINK%%[[#^jb19eanvzjc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jb19eanvzjc


>%%
>```annotation-json
>{"created":"2024-10-03T14:29:22.296Z","updated":"2024-10-03T14:29:22.296Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":44737,"end":44903},{"type":"TextQuoteSelector","exact":"scrolling system was preferred by most users, with 66% of users ranking itas their most preferred page-turning system and no users ranking it as their leastpreferred.","prefix":"e questionnaireresults that the ","suffix":" Figure 4.1 depicts userʼs exper"}]}]}
>```
>%%
>*%%PREFIX%%e questionnaireresults that the%%HIGHLIGHT%% ==scrolling system was preferred by most users, with 66% of users ranking itas their most preferred page-turning system and no users ranking it as their leastpreferred.== %%POSTFIX%%Figure 4.1 depicts userʼs exper*
>%%LINK%%[[#^n4q09gzxba|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^n4q09gzxba


>%%
>```annotation-json
>{"created":"2024-10-03T14:30:16.175Z","updated":"2024-10-03T14:30:16.175Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":45621,"end":45889},{"type":"TextQuoteSelector","exact":"One of the possiblecauses for this is an imperfect implementation of the trigger mechanism. As described inChapter 3, a rolling average of the last 15 gaze predictions was used to smooth out noise inthe gaze predictions. This can cause unexpected results in edge cases","prefix":"e turn was triggered too early. ","suffix":".One such edge case would be if "}]}]}
>```
>%%
>*%%PREFIX%%e turn was triggered too early.%%HIGHLIGHT%% ==One of the possiblecauses for this is an imperfect implementation of the trigger mechanism. As described inChapter 3, a rolling average of the last 15 gaze predictions was used to smooth out noise inthe gaze predictions. This can cause unexpected results in edge cases== %%POSTFIX%%.One such edge case would be if*
>%%LINK%%[[#^oqwsddtchwn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^oqwsddtchwn


>%%
>```annotation-json
>{"created":"2024-10-03T14:32:02.479Z","updated":"2024-10-03T14:32:02.479Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":46643,"end":46805},{"type":"TextQuoteSelector","exact":"Edge cases such as these were observedduring the user study, where a pianist glancing at the positioning of their right handregularly triggered an early page turn","prefix":"tom right corner of the screen. ","suffix":".There are several ways that edg"}]}]}
>```
>%%
>*%%PREFIX%%tom right corner of the screen.%%HIGHLIGHT%% ==Edge cases such as these were observedduring the user study, where a pianist glancing at the positioning of their right handregularly triggered an early page turn== %%POSTFIX%%.There are several ways that edg*
>%%LINK%%[[#^esfk5canozg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^esfk5canozg



>%%
>```annotation-json
>{"created":"2024-10-03T14:33:32.169Z","updated":"2024-10-03T14:33:32.169Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":47091,"end":47288},{"type":"TextQuoteSelector","exact":"A more robust solution would be to identify the types of eye movement the gazepredictions describe. If there is a rapid and considerable change in the gaze predictionsthis is likely to be a saccade","prefix":"g box for the trigger mechanism.","suffix":", an abrupt movement of the eye "}]}]}
>```
>%%
>*%%PREFIX%%g box for the trigger mechanism.%%HIGHLIGHT%% ==A more robust solution would be to identify the types of eye movement the gazepredictions describe. If there is a rapid and considerable change in the gaze predictionsthis is likely to be a saccade== %%POSTFIX%%, an abrupt movement of the eye*
>%%LINK%%[[#^4rws0qthxc5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4rws0qthxc5


>%%
>```annotation-json
>{"created":"2024-10-03T14:34:08.025Z","updated":"2024-10-03T14:34:08.025Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":47718,"end":47902},{"type":"TextQuoteSelector","exact":"did not causeas many issues for the scrolling system. One possible explanation for the scrolling systemhandling these cases is the gradual increases from one scrolling speed to another","prefix":"he double animation system, but ","suffix":".Another possible cause for the "}]}]}
>```
>%%
>*%%PREFIX%%he double animation system, but%%HIGHLIGHT%% ==did not causeas many issues for the scrolling system. One possible explanation for the scrolling systemhandling these cases is the gradual increases from one scrolling speed to another== %%POSTFIX%%.Another possible cause for the*
>%%LINK%%[[#^wydf78y7xa|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wydf78y7xa



>%%
>```annotation-json
>{"created":"2024-10-03T14:35:58.601Z","updated":"2024-10-03T14:35:58.601Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":48145,"end":48754},{"type":"TextQuoteSelector","exact":"This timer wasimplemented with a constant time for simplicity, but the speed at which a user reads thesheet music varies and is dependent on the tempo of the piece as well as the formatting ofthe sheet music. A simple but perhaps more effective solution might be a dynamicallychanging timer with the duration of the timer being dependent on the length of time ittakes the user to read the entire sheet of music. A more elegant solution could be to usecomputer vision techniques to identify the systems of music within the page and form apredictive model of where the user will be looking throughout the page. ","prefix":"ight hand corner of the screen. ","suffix":"This model canthen be updated wi"}]}]}
>```
>%%
>*%%PREFIX%%ight hand corner of the screen.%%HIGHLIGHT%% ==This timer wasimplemented with a constant time for simplicity, but the speed at which a user reads thesheet music varies and is dependent on the tempo of the piece as well as the formatting ofthe sheet music. A simple but perhaps more effective solution might be a dynamicallychanging timer with the duration of the timer being dependent on the length of time ittakes the user to read the entire sheet of music. A more elegant solution could be to usecomputer vision techniques to identify the systems of music within the page and form apredictive model of where the user will be looking throughout the page.== %%POSTFIX%%This model canthen be updated wi*
>%%LINK%%[[#^kbn704mlbf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kbn704mlbf



>%%
>```annotation-json
>{"created":"2024-10-03T14:37:52.132Z","updated":"2024-10-03T14:37:52.132Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":48991,"end":49492},{"type":"TextQuoteSelector","exact":"The scrolling system caused more jumps in the music than pauses in the music,where jumps in the music would be caused by the system scrolling too fast. One of thepossible reasons for this could be the design decision taken to only scroll the music in asingle direction. A simple solution would be to allow scrolling of the music in bothdirections, such that if a user was looking at the top of the screen the music would scrollfrom top to bottom, revealing music from previous pages in the sheet music","prefix":"ion model (Tabone et al., 2020).","suffix":".304.3.2 Gaze detection systemsC"}]}]}
>```
>%%
>*%%PREFIX%%ion model (Tabone et al., 2020).%%HIGHLIGHT%% ==The scrolling system caused more jumps in the music than pauses in the music,where jumps in the music would be caused by the system scrolling too fast. One of thepossible reasons for this could be the design decision taken to only scroll the music in asingle direction. A simple solution would be to allow scrolling of the music in bothdirections, such that if a user was looking at the top of the screen the music would scrollfrom top to bottom, revealing music from previous pages in the sheet music== %%POSTFIX%%.304.3.2 Gaze detection systemsC*
>%%LINK%%[[#^5r6qrg7o2xy|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5r6qrg7o2xy


>%%
>```annotation-json
>{"created":"2024-10-03T14:38:12.214Z","updated":"2024-10-03T14:38:12.214Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":49594,"end":49625},{"type":"TextQuoteSelector","exact":"SeeSo isgenerally more accurate","prefix":"ion systems it is apparent that ","suffix":", as shown by the lower dot erro"}]}]}
>```
>%%
>*%%PREFIX%%ion systems it is apparent that%%HIGHLIGHT%% ==SeeSo isgenerally more accurate== %%POSTFIX%%, as shown by the lower dot erro*
>%%LINK%%[[#^zc21to25fe|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zc21to25fe


>%%
>```annotation-json
>{"created":"2024-10-03T14:38:42.939Z","updated":"2024-10-03T14:38:42.939Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":49673,"end":49777},{"type":"TextQuoteSelector","exact":"The increase inaccuracy doesnʼt appear to be correlated to an increase in page-turning performancethough","prefix":"e lower dot error in Table 4.4. ","suffix":"; SeeSo performs better than iTr"}]}]}
>```
>%%
>*%%PREFIX%%e lower dot error in Table 4.4.%%HIGHLIGHT%% ==The increase inaccuracy doesnʼt appear to be correlated to an increase in page-turning performancethough== %%POSTFIX%%; SeeSo performs better than iTr*
>%%LINK%%[[#^tn3hlulkkjc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tn3hlulkkjc


>%%
>```annotation-json
>{"created":"2024-10-03T14:38:48.242Z","updated":"2024-10-03T14:38:48.242Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":49967,"end":50133},{"type":"TextQuoteSelector","exact":"This might suggest that the implementation of a page-turning systemmatters more than the accuracy of the gaze detections system with regard to page-turningperformance","prefix":" music forthe scrolling system. ","suffix":".Table 4.4 also shows that the a"}]}]}
>```
>%%
>*%%PREFIX%%music forthe scrolling system.%%HIGHLIGHT%% ==This might suggest that the implementation of a page-turning systemmatters more than the accuracy of the gaze detections system with regard to page-turningperformance== %%POSTFIX%%.Table 4.4 also shows that the a*
>%%LINK%%[[#^rguwfbunf3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rguwfbunf3


>%%
>```annotation-json
>{"created":"2024-10-03T14:40:04.254Z","updated":"2024-10-03T14:40:04.254Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":51552,"end":51670},{"type":"TextQuoteSelector","exact":"it was noted that as the distance from thepoint of regard to the camera increased the accuracy of the system decreased","prefix":"hich introduced iTracker, where ","suffix":".31It should also be noted that "}]}]}
>```
>%%
>*%%PREFIX%%hich introduced iTracker, where%%HIGHLIGHT%% ==it was noted that as the distance from thepoint of regard to the camera increased the accuracy of the system decreased== %%POSTFIX%%.31It should also be noted that*
>%%LINK%%[[#^jvgn4tqqvy|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jvgn4tqqvy



>%%
>```annotation-json
>{"created":"2024-10-03T14:40:52.421Z","updated":"2024-10-03T14:40:52.421Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":51706,"end":52026},{"type":"TextQuoteSelector","exact":"performance of both gaze detection systems mayhave suffered due to the unrestricted lighting conditions during the user study, as well asthe unrestricted relative positioning of the user and the device. A lack of person-specificcalibration or training of the two gaze detection systems could also be a contributingfactor","prefix":"t should also be noted that the ","suffix":".One possible solution to this d"}]}]}
>```
>%%
>*%%PREFIX%%t should also be noted that the%%HIGHLIGHT%% ==performance of both gaze detection systems mayhave suffered due to the unrestricted lighting conditions during the user study, as well asthe unrestricted relative positioning of the user and the device. A lack of person-specificcalibration or training of the two gaze detection systems could also be a contributingfactor== %%POSTFIX%%.One possible solution to this d*
>%%LINK%%[[#^2etzb8eswwn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2etzb8eswwn


>%%
>```annotation-json
>{"created":"2024-10-03T14:43:55.486Z","updated":"2024-10-03T14:43:55.486Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":52136,"end":52434},{"type":"TextQuoteSelector","exact":"to design the application to be used with the tablet deviceupside down. The front-facing camera would then be at the bottom of the screen, muchcloser to the bottom right hand corner of the screen and potentially resulting in increasedaccuracy in the gaze predictions in the bottom right hand corner","prefix":"screenfor page-turning would be ","suffix":".4.3.3 SummaryThe performance of"}]}]}
>```
>%%
>*%%PREFIX%%screenfor page-turning would be%%HIGHLIGHT%% ==to design the application to be used with the tablet deviceupside down. The front-facing camera would then be at the bottom of the screen, muchcloser to the bottom right hand corner of the screen and potentially resulting in increasedaccuracy in the gaze predictions in the bottom right hand corner== %%POSTFIX%%.4.3.3 SummaryThe performance of*
>%%LINK%%[[#^bvw3aq3xr4r|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bvw3aq3xr4r


>%%
>```annotation-json
>{"created":"2024-10-03T14:44:52.766Z","updated":"2024-10-03T14:44:52.766Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":52881,"end":52946},{"type":"TextQuoteSelector","exact":" scrolling system requires the least accuracy in gaze predictions","prefix":"m the gaze detectionsystems. The","suffix":", where thesystem only needs to "}]}]}
>```
>%%
>*%%PREFIX%%m the gaze detectionsystems. The%%HIGHLIGHT%% ==scrolling system requires the least accuracy in gaze predictions== %%POSTFIX%%, where thesystem only needs to*
>%%LINK%%[[#^twf8jv248x|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^twf8jv248x


>%%
>```annotation-json
>{"created":"2024-10-03T14:47:07.908Z","updated":"2024-10-03T14:47:07.908Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":53196,"end":53421},{"type":"TextQuoteSelector","exact":"The single animation systemrequired the most accuracy from the gaze detection systems, with the smallest boundingbox for triggering animations of the three systems and correspondingly the worstperformance of the three systems","prefix":"r each animation in Figure 3.4. ","suffix":". Trends were identified in the "}]}]}
>```
>%%
>*%%PREFIX%%r each animation in Figure 3.4.%%HIGHLIGHT%% ==The single animation systemrequired the most accuracy from the gaze detection systems, with the smallest boundingbox for triggering animations of the three systems and correspondingly the worstperformance of the three systems== %%POSTFIX%%. Trends were identified in the*
>%%LINK%%[[#^5eed36l4da5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5eed36l4da5


>%%
>```annotation-json
>{"created":"2024-10-03T14:50:46.986Z","updated":"2024-10-03T14:50:46.986Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":53423,"end":53620},{"type":"TextQuoteSelector","exact":"Trends were identified in the distribution of gazeprediction errors, where a correlation was drawn between the on-screen location of auser's point of regard and the accuracy of the gaze prediction.","prefix":"rformance of the three systems. ","suffix":" Additionally severalpossible im"}]}]}
>```
>%%
>*%%PREFIX%%rformance of the three systems.%%HIGHLIGHT%% ==Trends were identified in the distribution of gazeprediction errors, where a correlation was drawn between the on-screen location of auser's point of regard and the accuracy of the gaze prediction.== %%POSTFIX%%Additionally severalpossible im*
>%%LINK%%[[#^cwa76sarru|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cwa76sarru


>%%
>```annotation-json
>{"created":"2024-10-03T14:55:29.273Z","updated":"2024-10-03T14:55:29.273Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":55608,"end":55644},{"type":"TextQuoteSelector","exact":"ncorporating audio as an extra input","prefix":" focus on; a major such area isi","suffix":" in determining a user's positio"}]}]}
>```
>%%
>*%%PREFIX%%focus on; a major such area isi%%HIGHLIGHT%% ==ncorporating audio as an extra input== %%POSTFIX%%in determining a user's positio*
>%%LINK%%[[#^bk26eksm2bl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bk26eksm2bl


>%%
>```annotation-json
>{"created":"2024-10-03T14:56:06.403Z","updated":"2024-10-03T14:56:06.403Z","document":{"title":"Dissertation","link":[{"href":"urn:x-pdf:cd4b85925a25cef96a53b538f0b9a013"},{"href":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf"}],"documentFingerprint":"cd4b85925a25cef96a53b538f0b9a013"},"uri":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","target":[{"source":"vault:/Research & Innovation/group/TCD-SCSS-DISSERTATION-2022-023.pdf","selector":[{"type":"TextPositionSelector","start":56012,"end":56173},{"type":"TextQuoteSelector","exact":"Another situation where audio would be useful is determining when a user hasglanced away from the music and when the user has stopped playing the piece altogethe","prefix":"amining changesin audio levels. ","suffix":"r. With the33current implementat"}]}]}
>```
>%%
>*%%PREFIX%%amining changesin audio levels.%%HIGHLIGHT%% ==Another situation where audio would be useful is determining when a user hasglanced away from the music and when the user has stopped playing the piece altogethe== %%POSTFIX%%r. With the33current implementat*
>%%LINK%%[[#^wtpb3rk9jk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wtpb3rk9jk
