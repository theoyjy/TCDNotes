- A Triangle has 3 vertices and a normal
- *Vertex Buffer* contains all the vertices related to the obj
- Modelling Programs: create 3D models
- Scanning Tech:
	- Photogrammetry: 
	  take photos of an obj from all angles, different heights under multiple lighting conditions. Basically it's trying to subtract the lighting effect on the objects, so we can apply light on the model later on.
	- Structured light scanning
	- Laser Scanning:
	  Using the time for light to travel from cam to surface, to figure out the depth of points.
	- Gaussian Splatting:
	  Sparce Point Cloud, each sparce has its own shape and color.

>[!info] Rendering
>The process by which a cp creates images from models of objects
>And It's all Graphics Pipeline's job.

- Fixed Function Pipeline -- OpenGL 1
  Lack of programmability
### Graphics Programmable Pipeline

Introduce the Fragment Shader for much more *lightings*, *textures*.
#### Coarse Division:
1. Application Stage:
   - Developer has full control
     Setting up on the vertex and programs. Basically ends up with Vertex buffer
2. Geometry Stage
	1. Vertex Shader(Programmable)
	   1. Model & View Transformation
	      - Scale objs to the suitable scale.
	      - Place objs in the desired locations
	      - Place camera in the right place.
	   2. Vertex Shading
	      - focus on the contribution of light, which means the effect of a light on a material
	      - don't care about the polygons at this stage, only on the vertices, vertices has material, color info
	      - It's not the good enough for lighting, fancy effect should be done later on
	   3. Projection
	      - Determine how 3D objs being view in 2D
	      - Perspective or orthographic viewing
	2. Clipping
	   Eliminate the objs outside of the frustrum
	3. Screening Mapping
	   Convert 2D Normalized Coordinates(range from -1 to 1) to 2D Screen/pixel(0,0) to (x resolution, y resolution)
3. The Rasterized Stage

